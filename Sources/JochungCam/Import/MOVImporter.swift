import Foundation
import AVFoundation
import CoreGraphics
import VideoToolbox

// ğŸ¬ ë¦¬ë¦¬ì˜ ì™„ë²½í•œ MOVâ†’GIF ë³€í™˜ ì‹œìŠ¤í…œ

@MainActor
class MOVImporter: ObservableObject {
    
    @Published var isImporting = false
    @Published var progress: Double = 0.0
    @Published var currentOperation: String = ""
    
    private var importTask: Task<[GIFFrame]?, Error>?
    
    /// ì™„ë²½í•œ MOVâ†’GIF ë³€í™˜ (ìë™ ìµœì í™”)
    func importMOV(from url: URL, targetFPS: Int = 15) async throws -> [GIFFrame]? {
        
        importTask?.cancel()
        
        importTask = Task {
            await performMOVImport(url: url, targetFPS: targetFPS)
        }
        
        return try await importTask?.value
    }
    
    private func performMOVImport(url: URL, targetFPS: Int) async -> [GIFFrame]? {
        isImporting = true
        progress = 0.0
        defer {
            isImporting = false
            progress = 0.0
            currentOperation = ""
        }
        
        do {
            // 1ë‹¨ê³„: ë¹„ë””ì˜¤ ë¶„ì„
            currentOperation = "ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì¤‘..."
            progress = 0.1
            
            let asset = AVAsset(url: url)
            let videoInfo = try await analyzeVideo(asset)
            
            if Task.isCancelled { return nil }
            
            // 2ë‹¨ê³„: ìµœì í™”ëœ í”„ë ˆì„ ì¶”ì¶œ ì„¤ì • ê³„ì‚°
            currentOperation = "ìµœì í™” ì„¤ì • ê³„ì‚° ì¤‘..."
            progress = 0.2
            
            let extractionSettings = calculateOptimalExtractionSettings(
                videoInfo: videoInfo,
                targetFPS: targetFPS
            )
            
            if Task.isCancelled { return nil }
            
            // 3ë‹¨ê³„: ê³ í’ˆì§ˆ í”„ë ˆì„ ì¶”ì¶œ
            currentOperation = "ê³ í’ˆì§ˆ í”„ë ˆì„ ì¶”ì¶œ ì¤‘..."
            progress = 0.3
            
            let frames = try await extractFramesOptimized(
                from: asset,
                settings: extractionSettings
            )
            
            if Task.isCancelled { return nil }
            
            // 4ë‹¨ê³„: í›„ì²˜ë¦¬ ìµœì í™”
            currentOperation = "í”„ë ˆì„ í›„ì²˜ë¦¬ ì¤‘..."
            progress = 0.8
            
            let optimizedFrames = await postProcessFrames(frames, settings: extractionSettings)
            
            progress = 1.0
            currentOperation = "ì™„ë£Œ"
            
            return optimizedFrames
            
        } catch {
            print("MOV ì„í¬íŠ¸ ì‹¤íŒ¨: \(error)")
            return nil
        }
    }
    
    /// ë¹„ë””ì˜¤ ë¶„ì„
    private func analyzeVideo(_ asset: AVAsset) async throws -> VideoInfo {
        await Task.yield()
        
        let duration = try await asset.load(.duration)
        let videoTracks = try await asset.loadTracks(withMediaType: .video)
        
        guard let videoTrack = videoTracks.first else {
            throw ImportError.noVideoTrack
        }
        
        let naturalSize = try await videoTrack.load(.naturalSize)
        let nominalFrameRate = try await videoTrack.load(.nominalFrameRate)
        let timeRange = try await videoTrack.load(.timeRange)
        
        return VideoInfo(
            duration: CMTimeGetSeconds(duration),
            frameRate: nominalFrameRate,
            size: naturalSize,
            timeRange: timeRange,
            track: videoTrack
        )
    }
    
    /// ìµœì í™”ëœ ì¶”ì¶œ ì„¤ì • ê³„ì‚°
    private func calculateOptimalExtractionSettings(
        videoInfo: VideoInfo,
        targetFPS: Int
    ) -> ExtractionSettings {
        
        let videoDuration = videoInfo.duration
        let originalFPS = videoInfo.frameRate
        let originalSize = videoInfo.size
        
        // 1. í”„ë ˆì„ ê°„ê²© ê³„ì‚° (ìŠ¤ë§ˆíŠ¸ ì„œë¸Œìƒ˜í”Œë§)
        let frameInterval: Double
        if originalFPS > Float(targetFPS) {
            frameInterval = Double(originalFPS) / Double(targetFPS)
        } else {
            frameInterval = 1.0 // ì›ë³¸ FPSê°€ ë” ë‚®ìœ¼ë©´ ê·¸ëŒ€ë¡œ
        }
        
        // 2. í•´ìƒë„ ìµœì í™” (4Kâ†’1080p, 8Kâ†’1440p ë“±)
        let optimizedSize = calculateOptimalSize(originalSize)
        
        // 3. í’ˆì§ˆ ì„¤ì •
        let qualitySettings: [String: Any] = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
            kCVPixelBufferIOSurfacePropertiesKey as String: [:],
            kCVPixelBufferMetalCompatibilityKey as String: true
        ]
        
        // 4. ìµœëŒ€ í”„ë ˆì„ ìˆ˜ ê³„ì‚° (ë©”ëª¨ë¦¬ ë³´í˜¸)
        let estimatedFrameCount = Int(videoDuration * Double(targetFPS))
        let maxFrames = min(estimatedFrameCount, 3000) // ìµœëŒ€ 3000í”„ë ˆì„
        
        return ExtractionSettings(
            frameInterval: frameInterval,
            targetSize: optimizedSize,
            qualitySettings: qualitySettings,
            maxFrames: maxFrames,
            timeScale: CMTimeScale(600), // ë†’ì€ ì •ë°€ë„
            preferredTransform: .identity
        )
    }
    
    /// ìµœì  í•´ìƒë„ ê³„ì‚°
    private func calculateOptimalSize(_ originalSize: CGSize) -> CGSize {
        let width = originalSize.width
        let height = originalSize.height
        let aspectRatio = width / height
        
        // ë„ˆë¬´ í° í•´ìƒë„ëŠ” ìë™ ì¶•ì†Œ
        if width > 3840 { // 4K ì´ˆê³¼
            let newWidth: CGFloat = 1920 // 1080pë¡œ
            let newHeight = newWidth / aspectRatio
            return CGSize(width: newWidth, height: newHeight)
        } else if width > 2560 { // 1440p ì´ˆê³¼
            let newWidth: CGFloat = 1280 // 720pë¡œ
            let newHeight = newWidth / aspectRatio
            return CGSize(width: newWidth, height: newHeight)
        } else if width > 1920 { // 1080p ì´ˆê³¼
            let newWidth: CGFloat = 1280 // 720pë¡œ
            let newHeight = newWidth / aspectRatio
            return CGSize(width: newWidth, height: newHeight)
        }
        
        // ì´ë¯¸ ì ì ˆí•œ í¬ê¸°
        return originalSize
    }
    
    /// ìµœì í™”ëœ í”„ë ˆì„ ì¶”ì¶œ
    private func extractFramesOptimized(
        from asset: AVAsset,
        settings: ExtractionSettings
    ) async throws -> [GIFFrame] {
        
        let generator = AVAssetImageGenerator(asset: asset)
        generator.appliesPreferredTrackTransform = true
        generator.maximumSize = settings.targetSize
        
        // ê³ í’ˆì§ˆ ì„¤ì •
        generator.requestedTimeToleranceBefore = .zero
        generator.requestedTimeToleranceAfter = .zero
        
        // í”„ë ˆì„ ì‹œê°„ ë°°ì—´ ìƒì„±
        let duration = try await asset.duration
        let frameCount = min(settings.maxFrames, Int(CMTimeGetSeconds(duration) * Double(1.0 / settings.frameInterval)))
        let timeStep = CMTimeGetSeconds(duration) / Double(frameCount)
        
        var frameTimes: [NSValue] = []
        for i in 0..<frameCount {
            let time = CMTime(seconds: timeStep * Double(i), preferredTimescale: settings.timeScale)
            frameTimes.append(NSValue(time: time))
        }
        
        var extractedFrames: [GIFFrame] = []
        let frameDuration = 1.0 / Double(15) // ê¸°ë³¸ í”„ë ˆì„ ì§€ì† ì‹œê°„
        
        // ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¦ëŒ€
        let batchSize = 20
        for batch in frameTimes.chunked(into: batchSize) {
            if Task.isCancelled { throw ImportError.cancelled }
            
            // ë°°ì¹˜ë³„ í”„ë ˆì„ ì¶”ì¶œ
            let batchFrames = try await extractFrameBatch(
                generator: generator,
                times: batch,
                frameDuration: frameDuration
            )
            
            extractedFrames.append(contentsOf: batchFrames)
            
            // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = 0.3 + (Double(extractedFrames.count) / Double(frameCount)) * 0.5
            await Task.yield() // UI ë°˜ì‘ì„±
        }
        
        return extractedFrames
    }
    
    /// ë°°ì¹˜ í”„ë ˆì„ ì¶”ì¶œ
    private func extractFrameBatch(
        generator: AVAssetImageGenerator,
        times: [NSValue],
        frameDuration: TimeInterval
    ) async throws -> [GIFFrame] {
        
        return await withCheckedContinuation { continuation in
            var batchFrames: [GIFFrame] = []
            var completedCount = 0
            let totalCount = times.count
            
            generator.generateCGImagesAsynchronously(forTimes: times) { time, image, actualTime, result, error in
                defer {
                    completedCount += 1
                    if completedCount == totalCount {
                        continuation.resume(returning: batchFrames)
                    }
                }
                
                guard result == .succeeded,
                      let cgImage = image,
                      error == nil else {
                    print("í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨ at \(time): \(error?.localizedDescription ?? "unknown")")
                    return
                }
                
                let gifFrame = GIFFrame(image: cgImage, duration: frameDuration)
                batchFrames.append(gifFrame)
            }
        }
    }
    
    /// í›„ì²˜ë¦¬ ìµœì í™”
    private func postProcessFrames(
        _ frames: [GIFFrame],
        settings: ExtractionSettings
    ) async -> [GIFFrame] {
        
        await Task.yield()
        
        var optimizedFrames = frames
        
        // 1. ì‹œê°„ìˆœ ì •ë ¬ (ë¹„ë™ê¸° ì¶”ì¶œë¡œ ì¸í•œ ìˆœì„œ í˜¼ì¬ ë°©ì§€)
        optimizedFrames.sort { frame1, frame2 in
            // ì´ë¯¸ì§€ í•´ì‹œ ê¸°ë°˜ ê°„ë‹¨ ì •ë ¬ (ì‹¤ì œë¡œëŠ” ì‹œê°„ ì •ë³´ ì‚¬ìš©)
            return frame1.id.uuidString < frame2.id.uuidString
        }
        
        // 2. ì¤‘ë³µ í”„ë ˆì„ ì œê±° (ë” ì •í™•í•œ ì•Œê³ ë¦¬ì¦˜)
        optimizedFrames = await removeDuplicateFrames(optimizedFrames)
        
        // 3. í”„ë ˆì„ duration ë³´ì • (ì¼ì •í•˜ê²Œ)
        let targetDuration = 1.0 / 15.0 // 15fps
        for i in optimizedFrames.indices {
            optimizedFrames[i].duration = targetDuration
        }
        
        return optimizedFrames
    }
    
    /// ê³ ê¸‰ ì¤‘ë³µ í”„ë ˆì„ ì œê±°
    private func removeDuplicateFrames(_ frames: [GIFFrame]) async -> [GIFFrame] {
        guard frames.count > 2 else { return frames }
        
        var uniqueFrames: [GIFFrame] = [frames[0]]
        let threshold: UInt64 = 0x20202020 // ì•½ê°„ì˜ ì°¨ì´ëŠ” í—ˆìš©
        
        for i in 1..<frames.count {
            if Task.isCancelled { break }
            
            let currentFrame = frames[i]
            let lastFrame = uniqueFrames.last!
            
            // ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¹„êµ (í•´ì‹œ ê¸°ë°˜)
            let isDifferent = await compareImages(lastFrame.image, currentFrame.image, threshold: threshold)
            
            if isDifferent {
                uniqueFrames.append(currentFrame)
            } else {
                // ì¤‘ë³µ í”„ë ˆì„ì˜ durationì„ ì´ì „ í”„ë ˆì„ì— í•©ì‚°
                let lastIndex = uniqueFrames.count - 1
                uniqueFrames[lastIndex].duration += currentFrame.duration
            }
            
            if i % 10 == 0 {
                await Task.yield() // ì£¼ê¸°ì  ì–‘ë³´
            }
        }
        
        return uniqueFrames
    }
    
    /// ê³ ì† ì´ë¯¸ì§€ ë¹„êµ
    private func compareImages(_ image1: CGImage, _ image2: CGImage, threshold: UInt64) async -> Bool {
        guard image1.width == image2.width,
              image1.height == image2.height else { return true }
        
        // ìƒ˜í”Œë§ ê¸°ë°˜ ë¹„êµ (ì„±ëŠ¥ ìµœì í™”)
        let sampleSize = 32 // 32x32 ìƒ˜í”Œ ê·¸ë¦¬ë“œ
        let stepX = max(1, image1.width / sampleSize)
        let stepY = max(1, image1.height / sampleSize)
        
        guard let data1 = extractImageSamples(image1, stepX: stepX, stepY: stepY),
              let data2 = extractImageSamples(image2, stepX: stepX, stepY: stepY) else {
            return true // ë¹„êµ ì‹¤íŒ¨ì‹œ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ ê°„ì£¼
        }
        
        let sampleCount = min(data1.count, data2.count)
        var diffCount = 0
        let maxDiffCount = sampleCount / 10 // 10% ì´ìƒ ë‹¤ë¥´ë©´ ë‹¤ë¥¸ ì´ë¯¸ì§€
        
        for i in 0..<sampleCount {
            let pixel1 = data1[i]
            let pixel2 = data2[i]
            
            // RGB ì°¨ì´ ê³„ì‚° (ê°„ì†Œí™”)
            let rDiff = abs(Int32(pixel1 >> 24) - Int32(pixel2 >> 24))
            let gDiff = abs(Int32((pixel1 >> 16) & 0xFF) - Int32((pixel2 >> 16) & 0xFF))
            let bDiff = abs(Int32((pixel1 >> 8) & 0xFF) - Int32((pixel2 >> 8) & 0xFF))
            
            if rDiff > 32 || gDiff > 32 || bDiff > 32 { // ì„ê³„ê°’ 32 (256ì˜ 1/8)
                diffCount += 1
                if diffCount > maxDiffCount {
                    return true // ì¶©ë¶„íˆ ë‹¤ë¦„
                }
            }
        }
        
        return false // ìœ ì‚¬í•¨
    }
    
    /// ì´ë¯¸ì§€ ìƒ˜í”Œ ì¶”ì¶œ
    private func extractImageSamples(_ image: CGImage, stepX: Int, stepY: Int) -> [UInt32]? {
        let width = image.width
        let height = image.height
        let pixelCount = width * height
        
        guard let pixelData = calloc(pixelCount, MemoryLayout<UInt32>.size) else { return nil }
        defer { free(pixelData) }
        
        let colorSpace = CGColorSpaceCreateDeviceRGB()
        guard let context = CGContext(
            data: pixelData,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue | CGBitmapInfo.byteOrder32Big.rawValue
        ) else { return nil }
        
        context.draw(image, in: CGRect(x: 0, y: 0, width: width, height: height))
        
        let buffer = pixelData.bindMemory(to: UInt32.self, capacity: pixelCount)
        
        // ìƒ˜í”Œë§
        var samples: [UInt32] = []
        for y in stride(from: 0, to: height, by: stepY) {
            for x in stride(from: 0, to: width, by: stepX) {
                let index = y * width + x
                if index < pixelCount {
                    samples.append(buffer[index])
                }
            }
        }
        
        return samples
    }
    
    func cancelImport() {
        importTask?.cancel()
        importTask = nil
        isImporting = false
        progress = 0.0
        currentOperation = ""
    }
}

// MARK: - ë°ì´í„° êµ¬ì¡°

struct VideoInfo {
    let duration: Double
    let frameRate: Float
    let size: CGSize
    let timeRange: CMTimeRange
    let track: AVAssetTrack
}

struct ExtractionSettings {
    let frameInterval: Double
    let targetSize: CGSize
    let qualitySettings: [String: Any]
    let maxFrames: Int
    let timeScale: CMTimeScale
    let preferredTransform: CGAffineTransform
}

enum ImportError: Error {
    case noVideoTrack
    case cancelled
    case invalidFile
    case memoryError
}

// MARK: - ìœ í‹¸ë¦¬í‹° í™•ì¥

extension Array {
    func chunked(into size: Int) -> [[Element]] {
        return stride(from: 0, to: count, by: size).map {
            Array(self[$0..<Swift.min($0 + size, count)])
        }
    }
}

extension AVAsset {
    var duration: CMTime {
        get async throws {
            try await load(.duration)
        }
    }
}